<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Prince face detection</title>
</head>
<body>
    <video id="videoInput" width="1200px" height="750px" autoplay style="display: none;"></video>
    <canvas id="canvasOutput" width="100%" height="100"></canvas>
    <div id="errorMessage"></div>

    <script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>

    <script>
        // Utils class to load external files into OpenCV.js
        class Utils {
            constructor(errorOutputId) {
                this.errorOutputId = errorOutputId;
            }

            createFileFromUrl(path, url, onload, onerror) {
                let xhr = new XMLHttpRequest();
                xhr.open('GET', url, true);
                xhr.responseType = 'arraybuffer';
                xhr.onload = () => {
                    if (xhr.status === 200) {
                        let data = new Uint8Array(xhr.response);
                        cv.FS_createDataFile('/', path, data, true, false, false);
                        onload();
                    } else {
                        if (onerror) {
                            onerror(xhr.status);
                        } else {
                            this.printError(`Failed to load ${url} status: ${xhr.status}`);
                        }
                    }
                };
                xhr.onerror = () => {
                    if (onerror) {
                        onerror(xhr.status);
                    } else {
                        this.printError(`Network error while loading ${url}`);
                    }
                };
                xhr.send();
            }

            printError(err) {
                if (this.errorOutputId !== undefined) {
                    document.getElementById(this.errorOutputId).innerHTML = 'Error: ' + err;
                } else {
                    console.log('Error: ', err);
                }
            }
        }

        let video = document.getElementById('videoInput');
        let streaming = false;

        function onOpenCvReady() {
            console.log("OpenCV.js is ready.");
            startVideoStream();
        }

        function startVideoStream() {
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    video.srcObject = stream;
                    video.play();
                    streaming = true;
                    setupFaceDetection();
                })
                .catch(err => {
                    console.log("An error occurred: " + err);
                });
        }

        function setupFaceDetection() {
            const utils = new Utils('errorMessage');
            const faceCascadePath = 'haarcascade_frontalface_default.xml';

            // Load the face detection model
            utils.createFileFromUrl(faceCascadePath, 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml', () => {
                let faceCascade = new cv.CascadeClassifier();
                faceCascade.load(faceCascadePath);

                // Set up the canvas and start processing frames
                let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                let gray = new cv.Mat();
                const FPS = 30;

                function processVideo() {
                    if (!streaming) {
                        src.delete();
                        gray.delete();
                        faceCascade.delete();
                        return;
                    }

                    // Capture a frame from the video feed
                    let cap = document.createElement('canvas');
                    cap.width = video.width;
                    cap.height = video.height;
                    cap.getContext('2d').drawImage(video, 0, 0, video.width, video.height);
                    src = cv.imread(cap);

                    // Convert the image to grayscale
                    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

                    // Detect faces
                    let faces = new cv.RectVector();
                    let msize = new cv.Size(0, 0);
                    faceCascade.detectMultiScale(gray, faces, 1.1, 3, 0, msize);

                    // Draw rectangles around detected faces
                    for (let i = 0; i < faces.size(); ++i) {
                        let face = faces.get(i);
                        let point1 = new cv.Point(face.x, face.y);
                        let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                        cv.rectangle(src, point1, point2, [255, 0, 0, 255], 2);
                    }

                    // Display the processed frame on canvas
                    cv.imshow('canvasOutput', src);

                    // Schedule the next frame processing
                    setTimeout(processVideo, 1000 / FPS);

                    // Cleanup
                    faces.delete();
                }
                processVideo();
            });
        }
    </script>
</body>
</html>
